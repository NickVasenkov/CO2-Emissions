{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac9bbcd8",
   "metadata": {},
   "source": [
    "In part 3 we'll standartize our residuals to catch uncatched variance.\n",
    "\n",
    "We'll evaluate performance of our models using Score calculation described in part 1, using TimeSeriesSplit cross-validation. However, we'll use a new function, ['functions/get_score_3.py'](functions/get_score_3.py). \n",
    "\n",
    "This function will predict scaled residuals ('emission_03_scaled') and then add to descaled predictions Trend and Seasonality to predict 'emission'. Then it will calculate the Score, in the same way as in part 1.\n",
    "\n",
    "I tested (testing is not included here) calculated in part 2 'Cycles' feature, but this way gave me lower Cross-val score with TimeSeriesSplit cross-validation, so I won't use 'Cycles'.\n",
    "\n",
    "Let's load the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0845676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.16 s\n",
      "Wall time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "global_variables = pd.read_csv('global_variables.csv', index_col=0)\n",
    "SEED = global_variables.loc[0, 'SEED']\n",
    "N_SPLITS = global_variables.loc[0, 'N_SPLITS']\n",
    "\n",
    "train_unprocessed = pd.read_csv('datasets/train.csv', index_col='ID_LAT_LON_YEAR_WEEK')\n",
    "test_unprocessed = pd.read_csv('datasets/test.csv', index_col='ID_LAT_LON_YEAR_WEEK')\n",
    "train_from_part_1 = pd.read_csv('new_datasets/train_from_part_1.csv', index_col='ID_LAT_LON_YEAR_WEEK')\n",
    "test_from_part_1 = pd.read_csv('new_datasets/test_from_part_1.csv', index_col='ID_LAT_LON_YEAR_WEEK')\n",
    "train_from_part_2 = pd.read_csv('new_datasets/train_from_part_2.csv', index_col='ID_LAT_LON_YEAR_WEEK')\n",
    "test_from_part_2 = pd.read_csv('new_datasets/test_from_part_2.csv', index_col='ID_LAT_LON_YEAR_WEEK')\n",
    "\n",
    "top_three_values = train_from_part_1.loc[:, 'Location_enc'].drop_duplicates().sort_values(ascending = False).head(3)\n",
    "top_three_locations = train_from_part_1.loc[train_from_part_1['Location_enc'].isin(top_three_values), 'Location'].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9569823",
   "metadata": {},
   "source": [
    "We'll create a DataFrame that won't be used in models training, but just for calculating the final prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0ec574",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_training_df = pd.concat([train_from_part_2, test_from_part_2])[['Trend', 'Seasonality', 'emission']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620bd9a7",
   "metadata": {},
   "source": [
    "Now, let's create 'train' and 'test' sets, that will contain all the variables we may use for our predictions, making sure we won't include variables that caclulate 'emission' from residuals, to avoid data leakage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e187f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_unprocessed.drop('emission', axis=1), \n",
    "                   train_from_part_2[['Location', 'WeekCount', 'date']]], axis=1)\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test = pd.concat([test_unprocessed, test_from_part_2[['Location', 'WeekCount', 'date']]], axis=1)\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f9c18d",
   "metadata": {},
   "source": [
    "Let's standartize the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727a81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train['emission_03_scaled'] = scaler.fit_transform(train_from_part_2[['emission_03']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91811d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[2,3]])\n",
    "\n",
    "x[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac18f64",
   "metadata": {},
   "source": [
    "## 00. Baseline.\n",
    "\n",
    "As a baseline, we'll fit LightGBM estimator to one feature, which will be just the column of 0's. We still should get quite a good Score (I remind you that lower is merrier), because predicted residuals will be transformed into 'emission' using features we calculated in Part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f217dd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10200653]\n",
      " [-0.10200653]\n",
      " [-0.10200653]\n",
      " ...\n",
      " [-0.10200653]\n",
      " [-0.10200653]\n",
      " [-0.10200653]]\n",
      "[-0.10200653]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (15807,) into shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:21\u001b[0m\n",
      "File \u001b[1;32m~\\My Drive\\5\\Kaggle\\CO2-Emissions\\functions\\get_score_3.py:71\u001b[0m, in \u001b[0;36mget_score_3\u001b[1;34m(global_variables, train, test, scaler, post_training_df, model, scores_df, update, comment, prepare_submission, n_splits, global_n_splits)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_pred[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# transform into the real target\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m train_pred[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m post_training_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m post_training_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeasonality\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     72\u001b[0m cv_pred[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m post_training_cv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m post_training_cv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeasonality\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Calculate scores and append to the scores lists\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2113\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2109\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_ufunc__\u001b[39m(\n\u001b[0;32m   2111\u001b[0m     \u001b[38;5;28mself\u001b[39m, ufunc: np\u001b[38;5;241m.\u001b[39mufunc, method: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m   2112\u001b[0m ):\n\u001b[1;32m-> 2113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arraylike\u001b[38;5;241m.\u001b[39marray_ufunc(\u001b[38;5;28mself\u001b[39m, ufunc, method, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:374\u001b[0m, in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;66;03m# e.g. test_multiindex_get_loc\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m     result \u001b[38;5;241m=\u001b[39m dispatch_ufunc_with_out(\u001b[38;5;28mself\u001b[39m, ufunc, method, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reconstruct(result)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduce\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# e.g. test.series.test_ufunc.test_reduce\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:467\u001b[0m, in \u001b[0;36mdispatch_ufunc_with_out\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m \u001b[43m_assign_where\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:477\u001b[0m, in \u001b[0;36m_assign_where\u001b[1;34m(out, result, where)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03mSet a ufunc result into 'out', masking with a 'where' argument if necessary.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;66;03m# no 'where' arg passed to ufunc\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m     out[:] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    479\u001b[0m     np\u001b[38;5;241m.\u001b[39mputmask(out, where, result)\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (15807,) into shape (1,)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "study_number = '00'\n",
    "\n",
    "scores_df = pd.DataFrame({'Comment': [], 'Train Score': [], 'Cross-val Score': [], 'Test RMSE': []})\n",
    "\n",
    "train_selected = pd.DataFrame(index=train.index, columns=['dummy', 'emission_03_scaled'])\n",
    "train_selected['dummy'] = 0\n",
    "train_selected['emission_03_scaled'] = train['emission_03_scaled']\n",
    "test_selected = pd.DataFrame(index=test_unprocessed.index, columns=['dummy'])\n",
    "test_selected['dummy'] = 0\n",
    "\n",
    "\n",
    "# Instantiate the estimator\n",
    "# UNCOMMENT TO INSTALL LightGBM\n",
    "#!pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "model = lgb.LGBMRegressor(random_state=SEED, n_jobs=-1, n_estimators=10)\n",
    "\n",
    "# Calculate scores\n",
    "from functions.get_score_3 import get_score_3\n",
    "\n",
    "train_score, cross_score, cross_scores_std, submission = get_score_3(global_variables, train_selected, test_selected, \n",
    "                                                                     scaler,\n",
    "                                                                     post_training_df, model, scores_df,\n",
    "                                                                  comment=\"Part 3 Baseline\")\n",
    "\n",
    "submission.to_csv('submissions/submission_3_' + study_number + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8398cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Cross-val Score</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.32305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Comment  Train Score  Cross-val Score  Test RMSE\n",
       "0      NaN          NaN              NaN   29.32305"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.loc[int(study_number), 'Test RMSE'] = 29.32305\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438441fb",
   "metadata": {},
   "source": [
    "## 01. Location Median Target Encoding\n",
    "\n",
    "Next, we'll recalculate our 'Location_enc' feature, same as Part 1, but with respect to residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82bae2ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: emission_03'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m study_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m location_median \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memission_03\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[0;32m      5\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation_enc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(location_median)\n\u001b[0;32m      6\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation_enc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(location_median)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:1416\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise warning\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing with multiple keys (implicitly converted to a tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof keys) will be deprecated, use a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1413\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1414\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1415\u001b[0m     )\n\u001b[1;32m-> 1416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py:248\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m--> 248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m     subset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\n\u001b[0;32m    250\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m subset\u001b[38;5;241m.\u001b[39mndim\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: emission_03'"
     ]
    }
   ],
   "source": [
    "study_number = '01'\n",
    "\n",
    "location_median = train.groupby('Location')['emission_03'].median()\n",
    "\n",
    "train['Location_enc'] = train['Location'].map(location_median)\n",
    "test['Location_enc'] = test['Location'].map(location_median)\n",
    "\n",
    "feature_name = 'Location_enc'\n",
    "for data in [train, test]:\n",
    "    print(data[feature_name].info())\n",
    "    print(data[feature_name].describe())\n",
    "    print('Unique Values and their count:')\n",
    "    print(data[feature_name].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef97b304",
   "metadata": {},
   "source": [
    "Let's test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6923ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "selected_columns = ['Location_enc']\n",
    "\n",
    "train_selected = train[selected_columns]\n",
    "train_selected = pd.concat([train_selected, train['emission_03']], axis=1)\n",
    "test_selected =  test[selected_columns]\n",
    "\n",
    "#Calculate scores\n",
    "train_score, cross_score, cross_scores_std, submission = get_score_3(global_variables, train_selected, test_selected, \n",
    "                                                                     post_training_df, model, scores_df,\n",
    "                                                                  comment=\"Location_enc\")\n",
    "\n",
    "submission.to_csv('submissions/submission_3_' + study_number + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f620b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.loc[int(study_number), 'Test RMSE'] = np.nan\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c936ac",
   "metadata": {},
   "source": [
    "We don't see an improvement, so we won't use this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db755a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns.remove('Location_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15b586",
   "metadata": {},
   "source": [
    "## 02. Week of the year Median Target Encoding\n",
    "\n",
    "What if we do encoding on the 'week_no' feature? Potentially, it may catch some weekly common sesoanalities, if they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e439469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_number = '02'\n",
    "\n",
    "week_no_median = train.groupby('week_no')['emission_03'].median()\n",
    "\n",
    "train['week_no_enc'] = train['week_no'].map(week_no_median)\n",
    "test['week_no_enc'] = test['week_no'].map(week_no_median)\n",
    "\n",
    "feature_name = 'week_no_enc'\n",
    "for data in [train, test]:\n",
    "    print(data[feature_name].info())\n",
    "    print(data[feature_name].describe())\n",
    "    print('Unique Values and their count:')\n",
    "    print(data[feature_name].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a415f7",
   "metadata": {},
   "source": [
    "Let's test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e5bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "selected_columns.append('week_no_enc')\n",
    "\n",
    "train_selected = train[selected_columns]\n",
    "train_selected = pd.concat([train_selected, train['emission_03']], axis=1)\n",
    "test_selected =  test[selected_columns]\n",
    "\n",
    "\n",
    "#Calculate scores\n",
    "train_score, cross_score, cross_scores_std, submission = get_score_3(global_variables, train_selected, test_selected, \n",
    "                                                                     post_training_df, model, scores_df,\n",
    "                                                                  comment=\"week_no_enc\")\n",
    "\n",
    "submission.to_csv('submissions/submission_3_' + study_number + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d6729",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.loc[int(study_number), 'Test RMSE'] = np.nan\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec756f2",
   "metadata": {},
   "source": [
    "No, that didn't work, maybe, there is no common seasonality left across all Locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246e951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns.remove('week_no_enc')\n",
    "\n",
    "train_selected = train[selected_columns]\n",
    "train_selected = pd.concat([train_selected, train['emission_03']], axis=1)\n",
    "test_selected =  test[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf92158",
   "metadata": {},
   "source": [
    "## 03. Most important features\n",
    "\n",
    "Let's estimate what features are most important for calculating our residues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c8117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "study_number = '03'\n",
    "\n",
    "## Train the model on the whole training set\n",
    "model.fit(train.drop(['emission_03', 'Location', 'date'], axis=1), train['emission_03'])\n",
    "\n",
    "feature_importances = pd.Series(data=model.feature_importances_, \n",
    "                                index=train.drop(['emission_03', 'Location', 'date'], axis=1).columns)\n",
    "\n",
    "print('Sorted feature importances (first 40):')\n",
    "feature_importances.sort_values(ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1454227",
   "metadata": {},
   "source": [
    "Few observations:\n",
    "\n",
    "-) The same model used way more features in calculating residues, than in calculating 'emission' (see Part 1).\n",
    "\n",
    "-) In combination with other features, 'Location_enc' and'week_no_enc' were useful for the model (although, they may still not pass the cross-validation testing)\n",
    "-) Even though we have 'Location_enc' and 'week_no_enc', week_no, latitudes and longitudes are still important\n",
    "\n",
    "Let's test a model based on some of the most important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "selected_columns = list(feature_importances.sort_values(ascending=False).index[:15])\n",
    "\n",
    "print('Selected columns: {}'.format(selected_columns))\n",
    "train_selected = train[selected_columns]\n",
    "train_selected = pd.concat([train_selected, train['emission_03']], axis=1)\n",
    "test_selected =  test[selected_columns]\n",
    "\n",
    "\n",
    "#Calculate scores\n",
    "train_score, cross_score, cross_scores_std, submission = get_score_3(global_variables, train_selected, test_selected, \n",
    "                                                                     post_training_df, model, scores_df,\n",
    "                                                                  comment=\"Most important features\")\n",
    "\n",
    "submission.to_csv('submissions/submission_3_' + study_number + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7423660",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.loc[int(study_number), 'Test RMSE'] = np.nan\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172c3ca",
   "metadata": {},
   "source": [
    "## 04. Geographical clustering\n",
    "\n",
    "The importance of latitude and longitude suggest benefits of creating location clusters: groups of locations that situated nearby. We'll also account for the 'emissions_03' to make clusters depending on similar emissions.\n",
    "\n",
    "First we'll create an elbow plot to detrmine an optimal number of clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa926d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "study_number = '04'\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Create cluster data\n",
    "cluster_data = train[['latitude', 'longitude', 'emission_03']]\n",
    "\n",
    "# Normalize data\n",
    "cluster_data = pd.DataFrame(StandardScaler().fit_transform(cluster_data), columns=['latitude', 'longitude', 'emission_03'],\n",
    "                           index=cluster_data.index)\n",
    "\n",
    "distortions = []\n",
    "num_clusters = range(1, 7)\n",
    "\n",
    "# Create a list of distortions from the kmeans function\n",
    "for i in num_clusters:\n",
    "    cluster_centers, distortion = kmeans(cluster_data, k_or_guess=i, seed=SEED)\n",
    "    distortions.append(distortion)\n",
    "\n",
    "# Create a DataFrame with two lists - num_clusters, distortions\n",
    "elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})\n",
    "\n",
    "# Creat a line plot of num_clusters and distortions\n",
    "sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
    "plt.xticks(num_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475bd5e",
   "metadata": {},
   "source": [
    "It seems that the optimal number of clusters is 2, but 4 can be also an option. Let's start with 2 clusters and look how they are situaded geographically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f19021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cluster_centers, distortion = kmeans(cluster_data, k_or_guess=2, seed=SEED)\n",
    "\n",
    "\n",
    "# Assign cluster labels\n",
    "cluster_data['cluster_labels'], _ = vq(cluster_data, cluster_centers)\n",
    "\n",
    "\n",
    "# Create a scatter plot\n",
    "sns.scatterplot(x='latitude', y='longitude', hue='cluster_labels', data=cluster_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c2c050",
   "metadata": {},
   "source": [
    "Note, that even though we used scaled 'emission_03' in our clustering, our clusters have nice geographical borders. Now, let's test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd46a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Save the cluster labels into train and set\n",
    "clusters = pd.concat([train['Location'], cluster_data['cluster_labels']], axis=1)\n",
    "clusters = pd.pivot_table(clusters, values=['cluster_labels'], index=['Location'])\n",
    "clusters = pd.Series(clusters['cluster_labels'])\n",
    "\n",
    "train['Location_cluster_2'] = train['Location'].map(clusters)\n",
    "test['Location_cluster_2'] = test['Location'].map(clusters)\n",
    "\n",
    "selected_columns = ['Location_cluster_2']\n",
    "\n",
    "print('Selected columns: {}'.format(selected_columns))\n",
    "train_selected = train[selected_columns]\n",
    "train_selected = pd.concat([train_selected, train['emission_03']], axis=1)\n",
    "test_selected =  test[selected_columns]\n",
    "\n",
    "#Calculate scores\n",
    "train_score, cross_score, cross_scores_std, submission = get_score_3(global_variables, train_selected, test_selected, \n",
    "                                                                     post_training_df, model, scores_df,\n",
    "                                                                  comment=\"Location_cluster_2\")\n",
    "\n",
    "submission.to_csv('submissions/submission_3_' + study_number + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b2570",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.loc[int(study_number), 'Test RMSE'] = np.nan\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec0247",
   "metadata": {},
   "source": [
    "That didn't work.\n",
    "\n",
    "## 05. Geographical clustering (4 clusters)\n",
    "\n",
    "Let's try 4 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2518375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "study_number = '05'\n",
    "\n",
    "selected_columns.remove('Location_cluster_2')\n",
    "\n",
    "cluster_centers, distortion = kmeans(cluster_data, k_or_guess=4, seed=SEED)\n",
    "\n",
    "\n",
    "# Assign cluster labels\n",
    "cluster_data['cluster_labels'], _ = vq(cluster_data, cluster_centers)\n",
    "\n",
    "\n",
    "# Create a scatter plot\n",
    "sns.scatterplot(x='latitude', y='longitude', hue='cluster_labels', data=cluster_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Save the cluster labels into train and set\n",
    "clusters = pd.concat([train['Location'], cluster_data['cluster_labels']], axis=1)\n",
    "clusters = pd.pivot_table(clusters, values=['cluster_labels'], index=['Location'])\n",
    "clusters = pd.Series(clusters['cluster_labels'])\n",
    "\n",
    "train['Location_cluster_4'] = train['Location'].map(clusters)\n",
    "test['Location_cluster_4'] = test['Location'].map(clusters)\n",
    "\n",
    "selected_columns = ['Location_cluster_4']\n",
    "\n",
    "print('Selected columns: {}'.format(selected_columns))\n",
    "train_selected = train[selected_columns]\n",
    "train_selected = pd.concat([train_selected, train['emission_03']], axis=1)\n",
    "test_selected =  test[selected_columns]\n",
    "\n",
    "#Calculate scores\n",
    "train_score, cross_score, cross_scores_std, submission = get_score_3(global_variables, train_selected, test_selected, \n",
    "                                                                     post_training_df, model, scores_df,\n",
    "                                                                  comment=\"Location_cluster_4\")\n",
    "\n",
    "submission.to_csv('submissions/submission_3_' + study_number + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d69e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.loc[int(study_number), 'Test RMSE'] = np.nan\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b8dc45",
   "metadata": {},
   "source": [
    "That didn't work.\n",
    "\n",
    "To be sure, let's expore how our new features affect feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f71003",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model on the whole training set\n",
    "model.fit(train.drop(['emission_03', 'Location', 'date'], axis=1), train['emission_03'])\n",
    "\n",
    "feature_importances = pd.Series(data=model.feature_importances_, \n",
    "                                index=train.drop(['emission_03', 'Location', 'date'], axis=1).columns)\n",
    "\n",
    "print('Sorted feature importances (first 40):')\n",
    "feature_importances.sort_values(ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d866f14",
   "metadata": {},
   "source": [
    "## 06. Filling NaNs based on 15 features\n",
    "\n",
    "First, we'll use KNNImputer to input missing values based on 15 most important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0391bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "study_number = '06'\n",
    "\n",
    "selected_columns = list(feature_importances.sort_values(ascending=False).index[:15])\n",
    "\n",
    "print('Selected columns: {}'.format(selected_columns))\n",
    "train_selected = train[selected_columns]\n",
    "train_selected = pd.concat([train_selected, train['emission_03']], axis=1)\n",
    "test_selected =  test[selected_columns]\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# define imputer\n",
    "imputer = KNNImputer(weights='distance')\n",
    "# fit on the dataset\n",
    "imputer.fit(train_selected.drop('emission_03', axis=1))\n",
    "# transform the datasets\n",
    "Xtrans = imputer.transform(train_selected.drop('emission_03', axis=1))\n",
    "train_selected_filled = pd.DataFrame(Xtrans, index=train_selected.index)\n",
    "train_selected_filled = pd.concat([train_selected_filled, train_selected['emission_03']], axis=1)\n",
    "train_selected_filled.columns = train_selected.columns\n",
    "Xtrans = imputer.transform(test_selected)\n",
    "test_selected_filled = pd.DataFrame(Xtrans, index=test_selected.index, columns=test_selected.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_selected_filled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25357c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate scores\n",
    "train_score, cross_score, cross_scores_std, submission = get_score_3(global_variables, train_selected_filled, \n",
    "                                                                     test_selected_filled, \n",
    "                                                                     post_training_df, model, scores_df,\n",
    "                                                                  comment=\"kNN imputing on 15\")\n",
    "\n",
    "submission.to_csv('submissions/submission_3_' + study_number + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.loc[int(study_number), 'Test RMSE'] = np.nan\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36224302",
   "metadata": {},
   "source": [
    "This filling works worse than NaNs.\n",
    "\n",
    "## 07. Filling NaNs based on 5 most important\n",
    "\n",
    "Now we'll use 5 most important features in calculating distances. They contain information about location and week of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e186b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "study_number = '07'\n",
    "\n",
    "selected_columns_5 = list(feature_importances.sort_values(ascending=False).index[:5])\n",
    "five_features_train = train[selected_columns_5]\n",
    "five_features_test =  test[selected_columns_5]\n",
    "\n",
    "# For each column with missing values\n",
    "for column in list(train_selected.columns[train_selected.isna().any()]):\n",
    "    \n",
    "    # Create a DataFrame of a feature with missing values and 5 most important features\n",
    "    df_to_fill_train = pd.concat([train[column], five_features_train], axis=1)\n",
    "    df_to_fill_test = pd.concat([test[column], five_features_test], axis=1)\n",
    "                                  \n",
    "    # fit on the dataset\n",
    "    imputer.fit(df_to_fill_train)\n",
    "    # transform the datasets\n",
    "    Xtrans = imputer.transform(df_to_fill_train)\n",
    "    train_selected_filled[column] = Xtrans[:, 0]\n",
    "    Xtrans = imputer.transform(df_to_fill_test)\n",
    "    test_selected_filled[column] = Xtrans[:, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21718c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_selected_filled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c6882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_selected_filled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate scores\n",
    "train_score, cross_score, cross_scores_std, submission = get_score_3(global_variables, train_selected_filled,\n",
    "                                                                     test_selected_filled, \n",
    "                                                                     post_training_df, model, scores_df,\n",
    "                                                                  comment=\"kNN imputing based on 5\")\n",
    "\n",
    "submission.to_csv('submissions/submission_3_' + study_number + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.loc[int(study_number), 'Test RMSE'] = np.nan\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ec2ae",
   "metadata": {},
   "source": [
    "As we can see, kNN imputing didn't work. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
